{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934e17c8",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "Caso for necessário, instalar a versão 2.2.3 do spacy para seguir a aula do professor:\n",
    "\n",
    "```bash\n",
    "    pip install spacy==2.2.3\n",
    "```\n",
    "\n",
    "Assim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2f5e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c370dd6",
   "metadata": {},
   "source": [
    "Realiza o download dos pacotes em português do spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
      "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt # Agora deve ser: pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5870c0",
   "metadata": {},
   "source": [
    "## Marcação POS\n",
    "\n",
    "- POS: (part-of-speech, partes da fala), atribui para as palavras partes da fala, como substantivos, adjetivos e verbos.\n",
    "- Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para realizar todo o processamento nos dados de texto\n",
    "pln = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a338c",
   "metadata": {},
   "source": [
    "Sempre que for necessário processar um texto é necessário coloca-lo dentro do objeto *pln* (variável que armazenou os modelos em português)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657829a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Estou aprendendo processamento de linguagem natural, curso do professor da IA Expert Academy, estudando em São Paulo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f30272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou AUX\n",
      "aprendendo VERB\n",
      "processamento NOUN\n",
      "de ADP\n",
      "linguagem NOUN\n",
      "natural ADJ\n",
      ", PUNCT\n",
      "curso NOUN\n",
      "do ADP\n",
      "professor NOUN\n",
      "da ADP\n",
      "IA PROPN\n",
      "Expert PROPN\n",
      "Academy PROPN\n",
      ", PUNCT\n",
      "estudando VERB\n",
      "em ADP\n",
      "São PROPN\n",
      "Paulo PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_) # pos_ verifica o \"part-of-speech\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec772e8",
   "metadata": {},
   "source": [
    "### Legenda\n",
    "\n",
    "- **lemma**: raiz da palavra\n",
    "- **pos**: parte da fala\n",
    "- **tag**: informações morfológicas, como se o verbo está no passado\n",
    "- **dep**: dependência sintática\n",
    "- **shape**: formato (maiúsculo, minúsculo, dígitos)\n",
    "- **alpha**: se é alfabético\n",
    "- **stop**: se é stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eedc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou</td>\n",
       "      <td>estar</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>aux</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aprendendo</td>\n",
       "      <td>aprender</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processamento</td>\n",
       "      <td>processamento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguagem</td>\n",
       "      <td>linguagem</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>natural</td>\n",
       "      <td>natural</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>curso</td>\n",
       "      <td>curso</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>appos</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do</td>\n",
       "      <td>de o</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professor</td>\n",
       "      <td>professor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>da</td>\n",
       "      <td>de o</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IA</td>\n",
       "      <td>IA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>XX</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Expert</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Academy</td>\n",
       "      <td>Academy</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>estudando</td>\n",
       "      <td>estudar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>em</td>\n",
       "      <td>em</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>São</td>\n",
       "      <td>São</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>Paulo</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palavra         lemma_   pos_   tag_       dep_ shape_  is_alpha  \\\n",
       "0           Estou          estar    AUX    AUX        aux  Xxxxx      True   \n",
       "1      aprendendo       aprender   VERB   VERB       ROOT   xxxx      True   \n",
       "2   processamento  processamento   NOUN   NOUN        obj   xxxx      True   \n",
       "3              de             de    ADP    ADP       case     xx      True   \n",
       "4       linguagem      linguagem   NOUN   NOUN       nmod   xxxx      True   \n",
       "5         natural        natural    ADJ    ADJ       amod   xxxx      True   \n",
       "6               ,              ,  PUNCT  PUNCT      punct      ,     False   \n",
       "7           curso          curso   NOUN   NOUN      appos   xxxx      True   \n",
       "8              do           de o    ADP    ADP       case     xx      True   \n",
       "9       professor      professor   NOUN   NOUN       nmod   xxxx      True   \n",
       "10             da           de o    ADP    ADP       case     xx      True   \n",
       "11             IA             IA  PROPN  PROPN       nmod     XX      True   \n",
       "12         Expert         Expert  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "13        Academy        Academy  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "14              ,              ,  PUNCT  PUNCT      punct      ,     False   \n",
       "15      estudando        estudar   VERB   VERB        acl   xxxx      True   \n",
       "16             em             em    ADP    ADP       case     xx      True   \n",
       "17            São            São  PROPN  PROPN        obl    Xxx      True   \n",
       "18          Paulo          Paulo  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "19              .              .  PUNCT  PUNCT      punct      .     False   \n",
       "\n",
       "    is_stop  \n",
       "0      True  \n",
       "1     False  \n",
       "2     False  \n",
       "3      True  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8      True  \n",
       "9     False  \n",
       "10     True  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16     True  \n",
       "17     True  \n",
       "18    False  \n",
       "19    False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tokens = [{'palavra': token.text, \n",
    "           'lemma_': token.lemma_, \n",
    "           'pos_': token.pos_, \n",
    "           'tag_': token.tag_, \n",
    "           'dep_': token.dep_, \n",
    "           'shape_': token.shape_, \n",
    "           'is_alpha': token.is_alpha, \n",
    "           'is_stop': token.is_stop}\n",
    "          for token in doc]\n",
    "\n",
    "df_tokens = pd.DataFrame.from_dict(tokens)\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588f45b",
   "metadata": {},
   "source": [
    "Adquirindo apenas entidades (nomes próprios):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be0984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA\n",
      "Expert\n",
      "Academy\n",
      "São\n",
      "Paulo\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ab500",
   "metadata": {},
   "source": [
    "## Lematização e stemização\n",
    "\n",
    "- **Lematização**: \"Lema\" de uma palavra de acordo com seu significado no dicionário - **palavra base** (análise vocabular e morfológica)\n",
    "    - Como por exemplo, para a palavra \"aprendendo\" a palavra base seria \"aprender\".\n",
    "\n",
    "- **Stemização**: Extração do **radical** das palavras.\n",
    "    - Como por exemplo, para a palavra \"aprendendo\" o radical extraído seria \"aprend\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f23e26",
   "metadata": {},
   "source": [
    "A Lematização realiza a análise morfológica das palavras.\n",
    "\n",
    "*morfológica: refere-se ao estudo da forma e estrutura*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67305514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>lemma_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou</td>\n",
       "      <td>estar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aprendendo</td>\n",
       "      <td>aprender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processamento</td>\n",
       "      <td>processamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguagem</td>\n",
       "      <td>linguagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>natural</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>curso</td>\n",
       "      <td>curso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do</td>\n",
       "      <td>de o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professor</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>da</td>\n",
       "      <td>de o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IA</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Expert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Academy</td>\n",
       "      <td>Academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>estudando</td>\n",
       "      <td>estudar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>em</td>\n",
       "      <td>em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>São</td>\n",
       "      <td>São</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palavra         lemma_\n",
       "0           Estou          estar\n",
       "1      aprendendo       aprender\n",
       "2   processamento  processamento\n",
       "3              de             de\n",
       "4       linguagem      linguagem\n",
       "5         natural        natural\n",
       "6               ,              ,\n",
       "7           curso          curso\n",
       "8              do           de o\n",
       "9       professor      professor\n",
       "10             da           de o\n",
       "11             IA             IA\n",
       "12         Expert         Expert\n",
       "13        Academy        Academy\n",
       "14              ,              ,\n",
       "15      estudando        estudar\n",
       "16             em             em\n",
       "17            São            São\n",
       "18          Paulo          Paulo\n",
       "19              .              ."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens[['palavra', 'lemma_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fceac01",
   "metadata": {},
   "source": [
    "Note que o lemma para cada uma das palavras abaixo é a mesma, ou seja, a morfologia de todas essas palavras levam para a palavra \"encontrar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe2f9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encontrar', 'encontrar', 'encontrar']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_2 = pln('encontrei encontraram encontrarão')\n",
    "[token.lemma_ for token in doc_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc358f8",
   "metadata": {},
   "source": [
    "### Comparação de stemização (NLTK - Natural Language ToolKit) x lematização (spaCy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36583146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/wolf/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp') # stemizador específico para trabalharmos com a língua portuguesa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfec44e",
   "metadata": {},
   "source": [
    "Quando é realizado a stemização, irá extrair apenas o radical das palavras.\n",
    "\n",
    "É possível que com o uso dessa técnica palavras com significados diferentes tenham um mesmo radical, algo que pode gerar confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5ede28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aprend'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "stemmer.stem('aprendendo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4bdf3",
   "metadata": {},
   "source": [
    "São Paulo ficou como \"paul\", não faz muito sentido extrair o radical de uma palavra que seria de um nome próprio.\n",
    "\n",
    "Com a lematização o significado da palavra é mantido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec4b02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou estar est\n",
      "aprendendo aprender aprend\n",
      "processamento processamento process\n",
      "de de de\n",
      "linguagem linguagem lingu\n",
      "natural natural natur\n",
      ", , ,\n",
      "curso curso curs\n",
      "do de o do\n",
      "professor professor profes\n",
      "da de o da\n",
      "IA IA ia\n",
      "Expert Expert expert\n",
      "Academy Academy academy\n",
      ", , ,\n",
      "estudando estudar estud\n",
      "em em em\n",
      "São São são\n",
      "Paulo Paulo paul\n",
      ". . .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spero-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
