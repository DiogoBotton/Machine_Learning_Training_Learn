{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934e17c8",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "Caso for necessário, instalar a versão 2.2.3 do spacy para seguir a aula do professor:\n",
    "\n",
    "```bash\n",
    "    pip install spacy==2.2.3\n",
    "```\n",
    "\n",
    "Assim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2f5e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c370dd6",
   "metadata": {},
   "source": [
    "Realiza o download dos pacotes em português do spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4007e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
      "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt # Agora deve ser: pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5870c0",
   "metadata": {},
   "source": [
    "## Marcação POS\n",
    "\n",
    "- POS: (part-of-speech, partes da fala), atribui para as palavras partes da fala, como substantivos, adjetivos e verbos.\n",
    "- Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a603a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para realizar todo o processamento nos dados de texto\n",
    "pln = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a338c",
   "metadata": {},
   "source": [
    "Sempre que for necessário processar um texto é necessário coloca-lo dentro do objeto *pln* (variável que armazenou os modelos em português)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657829a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Estou aprendendo processamento de linguagem natural, curso do professor da IA Expert Academy, estudando em São Paulo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f30272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou AUX\n",
      "aprendendo VERB\n",
      "processamento NOUN\n",
      "de ADP\n",
      "linguagem NOUN\n",
      "natural ADJ\n",
      ", PUNCT\n",
      "curso NOUN\n",
      "do ADP\n",
      "professor NOUN\n",
      "da ADP\n",
      "IA PROPN\n",
      "Expert PROPN\n",
      "Academy PROPN\n",
      ", PUNCT\n",
      "estudando VERB\n",
      "em ADP\n",
      "São PROPN\n",
      "Paulo PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_) # pos_ verifica o \"part-of-speech\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec772e8",
   "metadata": {},
   "source": [
    "### Legenda\n",
    "\n",
    "- **lemma**: raiz da palavra\n",
    "- **pos**: parte da fala\n",
    "- **tag**: informações morfológicas, como se o verbo está no passado\n",
    "- **dep**: dependência sintática\n",
    "- **shape**: formato (maiúsculo, minúsculo, dígitos)\n",
    "- **alpha**: se é alfabético\n",
    "- **stop**: se é stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3eedc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou</td>\n",
       "      <td>estar</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>aux</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aprendendo</td>\n",
       "      <td>aprender</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processamento</td>\n",
       "      <td>processamento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguagem</td>\n",
       "      <td>linguagem</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>natural</td>\n",
       "      <td>natural</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>curso</td>\n",
       "      <td>curso</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>appos</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do</td>\n",
       "      <td>de o</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professor</td>\n",
       "      <td>professor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>da</td>\n",
       "      <td>de o</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IA</td>\n",
       "      <td>IA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>XX</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Expert</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Academy</td>\n",
       "      <td>Academy</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>estudando</td>\n",
       "      <td>estudar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>em</td>\n",
       "      <td>em</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>São</td>\n",
       "      <td>São</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>Paulo</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palavra         lemma_   pos_   tag_       dep_ shape_  is_alpha  \\\n",
       "0           Estou          estar    AUX    AUX        aux  Xxxxx      True   \n",
       "1      aprendendo       aprender   VERB   VERB       ROOT   xxxx      True   \n",
       "2   processamento  processamento   NOUN   NOUN        obj   xxxx      True   \n",
       "3              de             de    ADP    ADP       case     xx      True   \n",
       "4       linguagem      linguagem   NOUN   NOUN       nmod   xxxx      True   \n",
       "5         natural        natural    ADJ    ADJ       amod   xxxx      True   \n",
       "6               ,              ,  PUNCT  PUNCT      punct      ,     False   \n",
       "7           curso          curso   NOUN   NOUN      appos   xxxx      True   \n",
       "8              do           de o    ADP    ADP       case     xx      True   \n",
       "9       professor      professor   NOUN   NOUN       nmod   xxxx      True   \n",
       "10             da           de o    ADP    ADP       case     xx      True   \n",
       "11             IA             IA  PROPN  PROPN       nmod     XX      True   \n",
       "12         Expert         Expert  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "13        Academy        Academy  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "14              ,              ,  PUNCT  PUNCT      punct      ,     False   \n",
       "15      estudando        estudar   VERB   VERB        acl   xxxx      True   \n",
       "16             em             em    ADP    ADP       case     xx      True   \n",
       "17            São            São  PROPN  PROPN        obl    Xxx      True   \n",
       "18          Paulo          Paulo  PROPN  PROPN  flat:name  Xxxxx      True   \n",
       "19              .              .  PUNCT  PUNCT      punct      .     False   \n",
       "\n",
       "    is_stop  \n",
       "0      True  \n",
       "1     False  \n",
       "2     False  \n",
       "3      True  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8      True  \n",
       "9     False  \n",
       "10     True  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16     True  \n",
       "17     True  \n",
       "18    False  \n",
       "19    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tokens = [{'palavra': token.text, \n",
    "           'lemma_': token.lemma_, \n",
    "           'pos_': token.pos_, \n",
    "           'tag_': token.tag_, \n",
    "           'dep_': token.dep_, \n",
    "           'shape_': token.shape_, \n",
    "           'is_alpha': token.is_alpha, \n",
    "           'is_stop': token.is_stop}\n",
    "          for token in doc]\n",
    "\n",
    "df_tokens = pd.DataFrame.from_dict(tokens)\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588f45b",
   "metadata": {},
   "source": [
    "Adquirindo apenas entidades (nomes próprios):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be0984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA\n",
      "Expert\n",
      "Academy\n",
      "São\n",
      "Paulo\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ab500",
   "metadata": {},
   "source": [
    "## Lematização e stemização\n",
    "\n",
    "- **Lematização**: \"Lema\" de uma palavra de acordo com seu significado no dicionário - **palavra base** (análise vocabular e morfológica)\n",
    "    - Como por exemplo, para a palavra \"aprendendo\" a palavra base seria \"aprender\".\n",
    "\n",
    "- **Stemização**: Extração do **radical** das palavras.\n",
    "    - Como por exemplo, para a palavra \"aprendendo\" o radical extraído seria \"aprend\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f23e26",
   "metadata": {},
   "source": [
    "A Lematização realiza a análise morfológica das palavras.\n",
    "\n",
    "*morfológica: refere-se ao estudo da forma e estrutura*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67305514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>lemma_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou</td>\n",
       "      <td>estar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aprendendo</td>\n",
       "      <td>aprender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processamento</td>\n",
       "      <td>processamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguagem</td>\n",
       "      <td>linguagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>natural</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>curso</td>\n",
       "      <td>curso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do</td>\n",
       "      <td>de o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>professor</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>da</td>\n",
       "      <td>de o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IA</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Expert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Academy</td>\n",
       "      <td>Academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>estudando</td>\n",
       "      <td>estudar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>em</td>\n",
       "      <td>em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>São</td>\n",
       "      <td>São</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palavra         lemma_\n",
       "0           Estou          estar\n",
       "1      aprendendo       aprender\n",
       "2   processamento  processamento\n",
       "3              de             de\n",
       "4       linguagem      linguagem\n",
       "5         natural        natural\n",
       "6               ,              ,\n",
       "7           curso          curso\n",
       "8              do           de o\n",
       "9       professor      professor\n",
       "10             da           de o\n",
       "11             IA             IA\n",
       "12         Expert         Expert\n",
       "13        Academy        Academy\n",
       "14              ,              ,\n",
       "15      estudando        estudar\n",
       "16             em             em\n",
       "17            São            São\n",
       "18          Paulo          Paulo\n",
       "19              .              ."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens[['palavra', 'lemma_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fceac01",
   "metadata": {},
   "source": [
    "Note que o lemma para cada uma das palavras abaixo é a mesma, ou seja, a morfologia de todas essas palavras levam para a palavra \"encontrar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe2f9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encontrar', 'encontrar', 'encontrar']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_2 = pln('encontrei encontraram encontrarão')\n",
    "[token.lemma_ for token in doc_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc358f8",
   "metadata": {},
   "source": [
    "### Comparação de stemização (NLTK - Natural Language ToolKit) x lematização (spaCy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36583146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/wolf/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp') # stemizador específico para trabalharmos com a língua portuguesa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfec44e",
   "metadata": {},
   "source": [
    "Quando é realizado a stemização, irá extrair apenas o radical das palavras.\n",
    "\n",
    "É possível que com o uso dessa técnica palavras com significados diferentes tenham um mesmo radical, algo que pode gerar confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ede28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aprend'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "stemmer.stem('aprendendo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4bdf3",
   "metadata": {},
   "source": [
    "São Paulo ficou como \"paul\", não faz muito sentido extrair o radical de uma palavra que seria de um nome próprio.\n",
    "\n",
    "Com a lematização o significado da palavra é mantido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec4b02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou estar est\n",
      "aprendendo aprender aprend\n",
      "processamento processamento process\n",
      "de de de\n",
      "linguagem linguagem lingu\n",
      "natural natural natur\n",
      ", , ,\n",
      "curso curso curs\n",
      "do de o do\n",
      "professor professor profes\n",
      "da de o da\n",
      "IA IA ia\n",
      "Expert Expert expert\n",
      "Academy Academy academy\n",
      ", , ,\n",
      "estudando estudar estud\n",
      "em em em\n",
      "São São são\n",
      "Paulo Paulo paul\n",
      ". . .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ff0ac",
   "metadata": {},
   "source": [
    "## Reconhecimento de entidades nomeadas\n",
    "\n",
    "- NER (Named-Entity Recognition).\n",
    "- Encontrar e classificar entidades no texto, dependendo da base de dados que foi utilizada para o treinamento (pessoa, localização, empresa, numéricos).\n",
    "- Usado em chatbots para saber o assunto falado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f3af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'A IBM é uma empresa dos Estados Unidos voltada para a área de informática. Sua sede no Brasil fica em São Paulo e a receita em 2018 foi de aproximadamente 320 bilhões de reais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e0bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99725f",
   "metadata": {},
   "source": [
    "Para acessar as entidades nomeadas, basta acessar pela propriedade *ents*.\n",
    "\n",
    "No caso, o algoritmo identificou que IBM é uma organização (ORG) e os demais são localizações (LOC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "751fe623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM ORG\n",
      "Estados Unidos LOC\n",
      "Brasil LOC\n",
      "São Paulo LOC\n"
     ]
    }
   ],
   "source": [
    "for entidade in doc.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8ec30b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IBM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " é uma empresa dos \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " voltada para a área de informática. Sua sede no \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " fica em \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e a receita em 2018 foi de aproximadamente 320 bilhões de reais</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc,\n",
    "                style='ent', # enfatizar as entidades\n",
    "                jupyter=True) # True para exibir com uma estilização no Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "063e8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Bill Gates nasceu em Seattle em 28/10/1955 e foi o criador da Microsoft'\n",
    "doc = pln(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b43f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates PER\n",
      "Seattle LOC\n",
      "Microsoft ORG\n"
     ]
    }
   ],
   "source": [
    "for entidade in doc.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c15aca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill Gates\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " nasceu em \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Seattle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " em 28/10/1955 e foi o criador da \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,\n",
    "                style='ent',\n",
    "                jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4617f4",
   "metadata": {},
   "source": [
    "Buscando apenas as entidades do tipo PER (pessoa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f180a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates\n"
     ]
    }
   ],
   "source": [
    "for entidade in doc.ents:\n",
    "    if entidade.label_ == 'PER':\n",
    "        print(entidade.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf94d6",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "- Palavras que aparecem com muita frequência e que não apresentam muito significado (e, a, de, da, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0be6ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'muitos', 'questão', 'umas', 'novos', 'estava', 'estás', 'portanto', 'cento', 'nuns', 'tão', 'pontos', 'oitava', 'teve', 'pela', 'ali', 'assim', 'estar', 'após', 'estou', 'pouco', 'sobre', 'fostes', 'estes', 'meio', 'tiveste', 'cuja', 'qual', 'isso', 'nossos', 'debaixo', 'dezoito', 'conhecido', 'seus', 'até', 'desse', 'vens', 'me', 'outros', 'o', 'fazeis', 'algumas', 'naquela', 'ainda', 'pelo', 'tentaram', 'ir', 'cujo', 'veja', 'boa', 'mil', 'posição', 'quando', 'fez', 'deverá', 'esse', 'dizer', 'ele', 'ver', 'ponto', 'povo', 'também', 'sabe', 'doze', 'nosso', 'essas', 'estiveram', 'fazes', 'adeus', 'vinda', 'novas', 'qualquer', 'estivestes', 'quieto', 'então', 'tendes', 'sim', 'tiveram', 'nos', 'bem', 'elas', 'tua', 'vais', 'tais', 'quê', 'eu', 'inicio', 'vós', 'desde', 'posso', 'dezassete', 'à', 'tempo', 'fomos', 'nove', 'lá', 'sexto', 'nada', 'lado', 'tipo', 'te', 'podem', 'dessa', 'máximo', 'possivelmente', 'catorze', 'ambos', 'no', 'cedo', 'em', 'vosso', 'não', 'já', 'apenas', 'forma', 'mesmo', 'esses', 'vários', 'contra', 'geral', 'dizem', 'todos', 'tanta', 'aos', 'deste', 'próximo', 'partir', 'meu', 'tivemos', 'vem', 'além', 'fazemos', 'conselho', 'falta', 'números', 'fui', 'cinco', 'final', 'neste', 'exemplo', 'teus', 'às', 'põem', 'vão', 'vêm', 'três', 'poder', 'nas', 'dar', 'dezanove', 'talvez', 'aquele', 'atrás', 'pode', 'área', 'muito', 'faz', 'somos', 'zero', 'cima', 'próxima', 'embora', 'segundo', 'estão', 'primeira', 'minhas', 'aí', 'estado', 'mas', 'novo', 'que', 'esteve', 'obrigada', 'aquelas', 'nova', 'temos', 'corrente', 'sexta', 'quarto', 'parte', 'primeiro', 'comprida', 'aquela', 'tivestes', 'dá', 'fazia', 'através', 'quero', 'direita', 'tem', 'possível', 'maiorias', 'vocês', 'treze', 'quinta', 'oito', 'aquilo', 'ambas', 'foram', 'ontem', 'pouca', 'nós', 'ter', 'meses', 'nossa', 'dos', 'meus', 'desta', 'demais', 'era', 'os', 'sou', 'daquele', 'disso', 'número', 'tentei', 'vinte', 'tarde', 'cá', 'saber', 'alguns', 'antes', 'certamente', 'seu', 'mal', 'ela', 'sei', 'tal', 'acerca', 'se', 'for', 'faço', 'onze', 'coisa', 'grandes', 'esta', 'cada', 'usar', 'vossas', 'dez', 'minha', 'põe', 'último', 'porém', 'fora', 'vos', 'tive', 'suas', 'parece', 'todas', 'nenhuma', 'vossos', 'baixo', 'nem', 'lugar', 'um', 'pegar', 'eventual', 'aqui', 'tanto', 'irá', 'dentro', 'sete', 'tenho', 'dezasseis', 'quieta', 'vez', 'maioria', 'inclusive', 'iniciar', 'sistema', 'ora', 'custa', 'apoio', 'deve', 'porquanto', 'usa', 'tudo', 'quer', 'estivemos', 'certeza', 'obrigado', 'valor', 'ligado', 'grande', 'fazer', 'agora', 'querem', 'menos', 'foste', 'sob', 'estive', 'devem', 'és', 'lhe', 'nossas', 'local', 'pelos', 'como', 'é', 'quatro', 'mais', 'nível', 'ser', 'a', 'sem', 'outras', 'porque', 'relação', 'e', 'nessa', 'outra', 'podia', 'vai', 'todo', 'apoia', 'contudo', 'fazem', 'terceiro', 'você', 'da', 'entre', 'seis', 'uns', 'maior', 'apontar', 'logo', 'sétimo', 'pois', 'puderam', 'na', 'estas', 'somente', 'pôde', 'poderá', 'do', 'aqueles', 'tu', 'próprio', 'quinto', 'teu', 'numa', 'têm', 'nunca', 'dão', 'oitavo', 'sempre', 'duas', 'sétima', 'está', 'onde', 'fará', 'por', 'tens', 'fim', 'ou', 'pelas', 'ademais', 'tentar', 'vindo', 'porquê', 'eles', 'grupo', 'bom', 'sois', 'perto', 'vezes', 'são', 'essa', 'daquela', 'as', 'bastante', 'mês', 'menor', 'quinze', 'ao', 'longe', 'terceira', 'algo', 'das', 'favor', 'depois', 'segunda', 'tente', 'estiveste', 'quem', 'uma', 'enquanto', 'quarta', 'de', 'para', 'estará', 'quais', 'isto', 'dois', 'num', 'breve', 'toda', 'este', 'des', 'com', 'conhecida', 'momento', 'só', 'diante', 'seria', 'comprido', 'caminho', 'quanto', 'foi', 'nesta', 'naquele', 'tuas', 'sua', 'diz', 'vossa', 'nesse'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f11c2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para a Lingua Portuguesa temos 416 stopwords.\n"
     ]
    }
   ],
   "source": [
    "print(f'Para a Lingua Portuguesa temos {len(STOP_WORDS)} stopwords.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a7a43",
   "metadata": {},
   "source": [
    "Verificando se uma palavra específica é stopword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68fc24b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln.vocab['é'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f8c63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln.vocab['caminhar'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa91ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Estou aprendendo processamento de linguagem natural, curso em Curitiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2450a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprendendo\n",
      "processamento\n",
      "linguagem\n",
      "natural\n",
      ",\n",
      "curso\n",
      "Curitiba\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if not pln.vocab[token.text].is_stop:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f4838",
   "metadata": {},
   "source": [
    "## Parsing de Dependências\n",
    "\n",
    "- Relação pai-filho entre as palavras.\n",
    "- Associação/contexto entre as palavras.\n",
    "\n",
    "A partir desta técnica é possível fazer a identificação do contexto da frase.\n",
    "\n",
    "Para um chat bot, por exemplo, será identificado os verbos (que seriam as ações que serão feitas) e indicará os nomes próprios ou localizações. Com isto, é possível adquirir o contexto (intenção) da frase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1bbf4",
   "metadata": {},
   "source": [
    "### Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c759660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Reserve uma passagem saindo de Guarulhos e chegando em Curitiba.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68350263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Guarulhos, Curitiba)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origem = doc[5]\n",
    "destino = doc[9]\n",
    "origem, destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b45d9ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[saindo, passagem, Reserve]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(origem.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f56eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[chegando, saindo, passagem, Reserve]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(destino.ancestors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89dcb1e",
   "metadata": {},
   "source": [
    "### Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f6951ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Reserva de uma mesa para o restaurante e de um táxi para o hotel.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79130677",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarefas = doc[3], doc[10]\n",
    "locais = doc[6], doc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcb6e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((mesa, táxi), (restaurante, hotel))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarefas, locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8bdfc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- restaurante\n",
      "mesa\n",
      "Reserva\n",
      "----- hotel\n",
      "táxi\n",
      "restaurante\n",
      "mesa\n",
      "Reserva\n"
     ]
    }
   ],
   "source": [
    "for local in locais:\n",
    "    print(5*'-', local)\n",
    "    for objeto in local.ancestors:\n",
    "        print(objeto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "331892eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserva de mesa é para o restaurante\n",
      "Reserva de táxi é para o hotel\n"
     ]
    }
   ],
   "source": [
    "for local in locais:\n",
    "    for objeto in local.ancestors:\n",
    "        if objeto in tarefas:\n",
    "            print(f'Reserva de {objeto} é para o {local}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703726d",
   "metadata": {},
   "source": [
    "O que vem depois da palavra \"restaurante\" (filhos dessa palavra, a direita)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e48b36cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[para, o, táxi]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[6].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0830c",
   "metadata": {},
   "source": [
    "### Exemplo 3: Visualizando as relações entre as palavras\n",
    "\n",
    "É possível analisar a relação entre as palavras de forma mais visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b08f9ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"bba84d0b3042427684fb93a1911dd07e-0\" class=\"displacy\" width=\"1310\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Reserva</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">uma</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">mesa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">restaurante</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">um</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">táxi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">hotel.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-0\" stroke-width=\"2px\" d=\"M160,182.0 C160,92.0 310.0,92.0 310.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-1\" stroke-width=\"2px\" d=\"M250,182.0 C250,137.0 305.0,137.0 305.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,184.0 L242,172.0 258,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-2\" stroke-width=\"2px\" d=\"M70,182.0 C70,47.0 315.0,47.0 315.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M315.0,184.0 L323.0,172.0 307.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,92.0 580.0,92.0 580.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,137.0 575.0,137.0 575.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-5\" stroke-width=\"2px\" d=\"M340,182.0 C340,47.0 585.0,47.0 585.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,184.0 L593.0,172.0 577.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-6\" stroke-width=\"2px\" d=\"M700,182.0 C700,47.0 945.0,47.0 945.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,184.0 L692,172.0 708,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-7\" stroke-width=\"2px\" d=\"M790,182.0 C790,92.0 940.0,92.0 940.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,184.0 L782,172.0 798,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-9\" stroke-width=\"2px\" d=\"M610,182.0 C610,2.0 950.0,2.0 950.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,184.0 L958.0,172.0 942.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-10\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,92.0 1210.0,92.0 1210.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,184.0 L1052,172.0 1068,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-11\" stroke-width=\"2px\" d=\"M1150,182.0 C1150,137.0 1205.0,137.0 1205.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,184.0 L1142,172.0 1158,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bba84d0b3042427684fb93a1911dd07e-0-12\" stroke-width=\"2px\" d=\"M970,182.0 C970,47.0 1215.0,47.0 1215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bba84d0b3042427684fb93a1911dd07e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1215.0,184.0 L1223.0,172.0 1207.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a4d769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Reserva]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[3].ancestors) # \"Reserva\" aponta para \"mesa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "882341ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[de, uma, restaurante]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[3].children) # \"Mesa\" aponta para \"de\", \"uma\" e \"restaurante\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5355cd7",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Qual cidade nós iremos visitar e qual cidade nós iremos ficar?\n",
    "\n",
    "Para responder essa pergunta podemos resgatar quais são as ações (verbos) da frase e locais (nomes próprios). A partir disto, podemos realizar um loop de repetição que passará pela lista de locais (nomes próprios) e irá adquirir as palavras que antecedem cada local (ancestrais).\n",
    "\n",
    "Baseado na proximidade, os verbos mais próximos dos nomes próprios estarão relacionados.\n",
    "\n",
    "A partir disto, é possível saber o que irá ser feito em cada uma das cidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edde6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pln('Que locais podemos visitar em Curitiba e para ficar em Guarulhos?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd214885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"f0d6d87ffcb34300838800a559690cac-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Que</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">locais</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">podemos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">visitar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">em</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Curitiba</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">ficar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">em</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Guarulhos?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 315.0,47.0 315.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310.0,139.0 L318.0,127.0 302.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,47.0 765.0,47.0 765.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-6\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,139.0 L692,127.0 708,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-7\" stroke-width=\"2px\" d=\"M340,137.0 C340,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f0d6d87ffcb34300838800a559690cac-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f0d6d87ffcb34300838800a559690cac-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8562853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[podemos, visitar, ficar]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoes = [token for token in doc if token.pos_ == \"VERB\"]\n",
    "acoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16ee1e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Curitiba, Guarulhos]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais = [token for token in doc if token.pos_ == \"PROPN\"]\n",
    "locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "437f1a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curitiba para visitar\n",
      "Guarulhos para ficar\n"
     ]
    }
   ],
   "source": [
    "for local in list(locais):\n",
    "    for verbo in local.ancestors:\n",
    "        if verbo in acoes:\n",
    "            print(f'{local} para {verbo}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c93ea",
   "metadata": {},
   "source": [
    "## Semelhanças entre palavras e textos\n",
    "\n",
    "- **Verifica se duas palavras são semelhantes ou logicamente relacionadas**.\n",
    "- Usa o algoritmo GloVe (Global Vectors for Word Representation).\n",
    "- Artigo original: [GloVe](https://nlp.stanford.edu/pubs/glove.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806cc60",
   "metadata": {},
   "source": [
    "### Exemplo 1: semelhança entre palavras e frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4afb5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pln('olá')\n",
    "p2 = pln('oi')\n",
    "p3 = pln('ou')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61ef7",
   "metadata": {},
   "source": [
    "Verificando se as palavras são semelhantes, retorna uma probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83955a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5972/4227870263.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  p1.similarity(p2), p2.similarity(p1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08208861947059631, 0.08208861947059631)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.similarity(p2), p2.similarity(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea69db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5972/1925673624.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  p1.similarity(p3), p2.similarity(p3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17541898787021637, 0.1645618975162506)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.similarity(p3), p2.similarity(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a68c4",
   "metadata": {},
   "source": [
    "### Semelhança entre frases\n",
    "\n",
    "Ideia de uso:\n",
    "\n",
    "É possível fazer **correções em palavras**, onde por exemplo, se houver algum erro de ortografia, como a palavra Curitiba estiver escrita como \"cutitiba\" (repetindo o *t*) ou \"curiiba\" (faltando a letra *t*) esse algoritmo poderia fazer a comparação de similaridade da palavra com erro ortografico e uma lista de cidades. A palavra que tiver maior probabilidade de similaridade pode ser a palavra correta, a partir disto poderia ser feito a correção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "706c6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = pln('Quando será lançado o novo filme?')\n",
    "texto2 = pln('O novo filme será lançado mês que vem.')\n",
    "texto3 = pln('Qual a cor do carro?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "450eeedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5972/144810851.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  texto1.similarity(texto2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8326985239982605"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1.similarity(texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "649c3a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5972/1685990419.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  texto1.similarity(texto3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47393396496772766"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1.similarity(texto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38087c29",
   "metadata": {},
   "source": [
    "### Exemplo 2\n",
    "\n",
    "Caso tivermos vários textos e for necessário calcular se um texto é similar a outro podemos utilizar a abordagem abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e96ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = pln('gato cachorro cavalo goiaba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00712acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Similaridade com gato ----\n",
      "gato é 43.62% similar a cachorro\n",
      "gato é 41.93% similar a cavalo\n",
      "gato é 5.08% similar a goiaba\n",
      "\n",
      "---- Similaridade com cachorro ----\n",
      "cachorro é 43.62% similar a gato\n",
      "cachorro é 58.27% similar a cavalo\n",
      "cachorro é 30.42% similar a goiaba\n",
      "\n",
      "---- Similaridade com cavalo ----\n",
      "cavalo é 41.93% similar a gato\n",
      "cavalo é 58.27% similar a cachorro\n",
      "cavalo é 36.83% similar a goiaba\n",
      "\n",
      "---- Similaridade com goiaba ----\n",
      "goiaba é 5.08% similar a gato\n",
      "goiaba é 30.42% similar a cachorro\n",
      "goiaba é 36.83% similar a cavalo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5972/95765263.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similaridade = txt1.similarity(txt2)\n"
     ]
    }
   ],
   "source": [
    "for txt1 in texto:\n",
    "    print(f'\\n---- Similaridade com {txt1} ----')\n",
    "    for txt2 in texto:\n",
    "        if txt2 == txt1:\n",
    "            continue\n",
    "        \n",
    "        similaridade = txt1.similarity(txt2)\n",
    "        print(f'{txt1} é {similaridade*100:.2f}% similar a {txt2}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b2c17",
   "metadata": {},
   "source": [
    "## Tokenização\n",
    "\n",
    "O processo de tokenização separa o texto em unidades menores chamadas de tokens, por exemplo, para uma frase: \"Eu vou comer hamburguer agora.\" os tokens seriam:\n",
    "- [\"Eu\", \"vou\", \"comer\", \"hamburguer\", \"agora\", \".\"]\n",
    "\n",
    "Também seria possível fazer com o *split* do próprio python, porém apenas com esta função o ponto (.) seria considerado parte da palavra \"agora\", exemplo:\n",
    "\n",
    "```py\n",
    "    texto = \"Eu vou comer hamburguer agora.\"\n",
    "    print(texto.split(' ')) # [\"Eu\", \"vou\", \"comer\", \"hamburguer\", \"agora.\"]\n",
    "```\n",
    "\n",
    "A biblioteca spaCy realiza a tokenização naturalmente, exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c30678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = pln(\"Eu vou comer hamburguer de carne agora.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b4f6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu\n",
      "vou\n",
      "comer\n",
      "hamburguer\n",
      "de\n",
      "carne\n",
      "agora\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for tok in texto:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15caec8c",
   "metadata": {},
   "source": [
    "Método tradicional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41edb851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eu', 'vou', 'comer', 'hamburguer', 'de', 'carne', 'agora.']\n"
     ]
    }
   ],
   "source": [
    "texto_raiz = \"Eu vou comer hamburguer de carne agora.\"\n",
    "print(texto_raiz.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232bccf",
   "metadata": {},
   "source": [
    "### Removendo stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ed24c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vou', 'comer', 'hamburguer', 'carne']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_final = []\n",
    "\n",
    "for tok in texto:\n",
    "    if not tok.is_stop and not tok.is_punct:\n",
    "        texto_final.append(tok.text)\n",
    "\n",
    "texto_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
